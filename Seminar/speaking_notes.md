## Adler

This is the central question we've been using to justify much of ecological
research, but the unfortunate truth is we very rarely attempt to make forecasts
for ecological systems in meaningfully testable ways.

When we do make predictions they tend to be very applied...

## Spatial Predictions

The first step in this direction is making predictions across space to learn
about the processes and predictors that might apply in time, and we're already
working on this.

## Forecast

The next step, and much more difficult and novel step, is to conduct actual
forecasting by making predictions for data that haven't been collected yet.

And doing so in such a way that we can actually evaluate whether or not those
forecasts are working.

## Data-intensive forecasts

And we're going to conduct these forecasts using the full weight of ecological
data at our disposal, which is something that's never been tried before.

By using large datasets with repeated sampling across space and through time the
models can learn from both dynamics within sites and responses to larger
environmental changes across space.

It also allows us to conduct 100,000s of forecasts simultaneously to help us
quickly learn what works and what doesn't, and allow us to evaluate not only the
central tendency of our predictions but also our estimates of their uncertainty.

## General data issues

To do this we'll have to confront a number of challenges that apply across
data-intensive disciplines. And in fact ecology serves as an excellent testing
ground for machine learning and other approaches because its data is often quite
complicated.

## 3 circles

But we won't be able to accomplish this alone, and by this I really mean the
broader goals of all of us in this room of bringing data-intensive approaches to
science more broadly. So, I'll be working to facilitate this shift in three
ways.

## NatureCast

Having provided scientists with the necessary skills, we need to provide them
with opportunities and motivation to develop these skills further and to come
together to solve shared problems. To facilitate this I plan to run a series of
ecological forecasting challenges based on the success of things like Kaggle
competitions, where everyone tries to do the best job of making forecasts for a
fixed set of data...

## Data Weaver

And finally, we tools to make this kind of science easier. My efforts in this
area focus on handling the broad variety of data needed to address interesting
questions, and my next major effort in this area will be to develop tools that
automate, in reproducible ways, the combination of multiple datasets. This is a
common issue across many areas of data-intensive research and will be developed
to work across a broad array of disciplines. By automating the process of
building combined datasets we can let scientists focus on the science aspect of
data science.
